{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkyiXqX70CM5",
        "outputId": "b6de8416-e8a2-41a3-f372-6ec53897abfc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.26.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.26.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.26.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5t_p1uA53wi",
        "outputId": "e0ffde9d-6e92-4a10-96eb-0487e21dcfaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf2\n",
            "  Downloading fpdf2-2.8.1-py2.py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from fpdf2) (0.7.1)\n",
            "Requirement already satisfied: Pillow!=9.2.*,>=6.2.2 in /usr/local/lib/python3.10/dist-packages (from fpdf2) (11.0.0)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from fpdf2) (4.55.0)\n",
            "Downloading fpdf2-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.8/227.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fpdf2\n",
            "Successfully installed fpdf2-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# truyenfull\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "import time\n",
        "import re\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Set up the Chrome WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')  # Run headless mode\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "# Function to extract content and navigate to the next part of the story\n",
        "def scrape_wattpad_story(url, pdf):\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "    try:\n",
        "        content = driver.find_element(By.CSS_SELECTOR, \".chapter-c\").text\n",
        "\n",
        "        #print(\"Story Content:\\n\", content)\n",
        "        h2_element = driver.find_element(By.CSS_SELECTOR, \"h2 > .chapter-title\").text\n",
        "        pdf.add_page()\n",
        "        pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\")\n",
        "        pdf.set_font(\"DejaVu\", size=20)\n",
        "        pdf.cell(0, 10, h2_element, ln=True, align=\"C\")\n",
        "        pdf.ln(10)\n",
        "        pdf.set_font(\"DejaVu\", size=14)\n",
        "        pdf.multi_cell(0, 10, content)\n",
        "    except Exception as e:\n",
        "        print(\"Failed to extract content:\", e)\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        navigation_div = driver.find_element(By.CSS_SELECTOR, \"#next_chap\")\n",
        "        # next_button = navigation_div.find_element(By.TAG_NAME, 'a')\n",
        "        next_url = navigation_div.get_attribute('href')\n",
        "        driver.get(next_url)\n",
        "        time.sleep(3)\n",
        "        scrape_wattpad_story(driver.current_url, pdf)\n",
        "    except Exception as e:\n",
        "        print(\"No more parts or failed to navigate:\", e)\n",
        "\n",
        "\n",
        "# Create a PDF instance\n",
        "pdf = FPDF()\n",
        "pdf.set_auto_page_break(auto=True, margin=15)\n",
        "pdf.add_page()\n",
        "pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\")\n",
        "\n",
        "# Start scraping from the given URL\n",
        "initial_url = \"https://truyenfull.io/van-an-phap-y-kieu-the/chuong-1/\"\n",
        "scrape_wattpad_story(initial_url, pdf)\n",
        "\n",
        "# Save the PDF file\n",
        "pdf_output_path = \"truyenhinhsu.pdf\"\n",
        "pdf.output(pdf_output_path)\n",
        "\n",
        "# Close the WebDriver\n",
        "driver.quit()\n",
        "print(f\"PDF saved as {pdf_output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9IvsJZo6ojI",
        "outputId": "93044b13-7453-47ff-ff1d-00abd70de74f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e69baf4b8bd5>:51: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
            "  pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\", uni=True)\n",
            "<ipython-input-4-e69baf4b8bd5>:26: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
            "  pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\", uni=True)\n",
            "<ipython-input-4-e69baf4b8bd5>:26: UserWarning: Core font or font already added 'dejavu': doing nothing\n",
            "  pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\", uni=True)\n",
            "<ipython-input-4-e69baf4b8bd5>:28: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=True use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
            "  pdf.cell(0, 10, h2_element, ln=True, align=\"C\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wattpad.vn\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "import time\n",
        "import re\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Set up the Chrome WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')  # Run headless mode\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "def scrape_wattpad_story(url, pdf):\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "    try:\n",
        "        content = driver.find_element(By.CSS_SELECTOR, \".container1 > p\").text\n",
        "\n",
        "        #print(\"Story Content:\\n\", content)\n",
        "        h2_element = driver.find_element(By.CSS_SELECTOR, \"h2.rv-chapt-title\").text\n",
        "        pdf.add_page()\n",
        "        pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\")\n",
        "        pdf.set_font(\"DejaVu\", size=20)\n",
        "        pdf.cell(0, 10, h2_element, ln=True, align=\"C\")\n",
        "        pdf.ln(10)\n",
        "\n",
        "        pdf.set_font(\"DejaVu\", size=14)\n",
        "        pdf.multi_cell(0, 10, content)\n",
        "    except Exception as e:\n",
        "        print(\"Failed to extract content:\", e)\n",
        "        return\n",
        "\n",
        "    # Navigate to the next part\n",
        "    try:\n",
        "        # Try to find <link rel=\"next\">\n",
        "        navigation_div = driver.find_element(By.CSS_SELECTOR, \".pagination.wp-pt0 > ul > li.next\")\n",
        "        next_button = navigation_div.find_element(By.TAG_NAME, 'a')\n",
        "        next_url = next_button.get_attribute('href')\n",
        "\n",
        "        # Navigate to the next URL\n",
        "        driver.get(next_url)\n",
        "        time.sleep(3)\n",
        "        scrape_wattpad_story(driver.current_url, pdf)\n",
        "    except Exception as e:\n",
        "        print(\"No more parts or failed to navigate:\", e)\n",
        "\n",
        "\n",
        "# Create a PDF instance\n",
        "pdf = FPDF()\n",
        "pdf.set_auto_page_break(auto=True, margin=15)\n",
        "pdf.add_page()\n",
        "pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\")\n",
        "\n",
        "# Start scraping from the given URL\n",
        "initial_url = \"https://wattpad.vn/danh-roi-ba-xa/chuong-1/\"\n",
        "scrape_wattpad_story(initial_url, pdf)\n",
        "\n",
        "# Save the PDF file\n",
        "pdf_output_path = \"danhroibaxa.pdf\"\n",
        "pdf.output(pdf_output_path)\n",
        "\n",
        "# Close the WebDriver\n",
        "driver.quit()\n",
        "print(f\"PDF saved as {pdf_output_path}\")"
      ],
      "metadata": {
        "id": "to4u7RJ40HXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wattpad.com\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "import time\n",
        "import re\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Set up the Chrome WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')  # Run headless mode\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "# Function to extract content and navigate to the next part of the story\n",
        "def scrape_wattpad_story(url, pdf):\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "    matchpage = re.search(r'page', url)\n",
        "    match = re.search(r'/(\\d+)-', url)\n",
        "    if matchpage:\n",
        "        result = match.group(1)\n",
        "        match1 = re.search(r'/(\\d+)$', url)\n",
        "        result1 = match1.group(1)\n",
        "        idpost = \"sp\" + result + \"-pg\" + result1\n",
        "    else:\n",
        "        result = match.group(1)\n",
        "        idpost = \"sp\" + result + \"-pg1\"\n",
        "\n",
        "    # Extract content from the specified class\n",
        "    try:\n",
        "        content = driver.find_element(By.ID, idpost).find_element(By.CLASS_NAME, \"panel-reading\").text\n",
        "        #print(\"Story Content:\\n\", content)\n",
        "        pdf.add_page()\n",
        "        pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\", uni=True)\n",
        "        pdf.set_font(\"DejaVu\", size=14)\n",
        "        pdf.multi_cell(0, 10, content)\n",
        "    except Exception as e:\n",
        "        print(\"Failed to extract content:\", e)\n",
        "        return\n",
        "\n",
        "    # Navigate to the next part\n",
        "    try:\n",
        "        # Try to find <link rel=\"next\">\n",
        "        next_link = driver.find_elements(By.CSS_SELECTOR, 'link[rel=\"next\"]')\n",
        "        if next_link:\n",
        "            next_url = next_link[0].get_attribute('href')\n",
        "        else:\n",
        "            # If not found, look for the navigation button\n",
        "            navigation_div = driver.find_element(By.ID, \"story-part-navigation\")\n",
        "            next_button = navigation_div.find_element(By.TAG_NAME, 'a')\n",
        "            next_url = next_button.get_attribute('href')\n",
        "\n",
        "        # Navigate to the next URL\n",
        "        driver.get(next_url)\n",
        "        time.sleep(3)\n",
        "        scrape_wattpad_story(driver.current_url, pdf)\n",
        "    except Exception as e:\n",
        "        print(\"No more parts or failed to navigate:\", e)\n",
        "\n",
        "\n",
        "# Create a PDF instance\n",
        "pdf = FPDF()\n",
        "pdf.set_auto_page_break(auto=True, margin=15)\n",
        "pdf.add_page()\n",
        "pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\", uni=True)\n",
        "pdf.set_font(\"DejaVu\", size=12)\n",
        "\n",
        "# Start scraping from the given URL\n",
        "initial_url = \"https://www.wattpad.com/1470471603-nam-kh%C3%A1nh-longfic-nh%C3%ACn-nh%C3%A2n-gian-ch%C6%B0%C6%A1ng-1\"\n",
        "scrape_wattpad_story(initial_url, pdf)\n",
        "\n",
        "# Save the PDF file\n",
        "pdf_output_path = \"nhinnhangian.pdf\"\n",
        "pdf.output(pdf_output_path)\n",
        "\n",
        "# Close the WebDriver\n",
        "driver.quit()\n",
        "print(f\"PDF saved as {pdf_output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1a423f-340a-4f89-a941-0c787a9b7867",
        "id": "KUpE1ai_Bms9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-ff343e223a1f>:70: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
            "  pdf.add_font(\"DejaVu\", \"\", \"21798841561.ttf\", uni=True)\n",
            "<ipython-input-5-ff343e223a1f>:39: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
            "  pdf.add_font(\"DejaVu\", \"\", \"21798841561.ttf\", uni=True)\n",
            "<ipython-input-5-ff343e223a1f>:39: UserWarning: Core font or font already added 'dejavu': doing nothing\n",
            "  pdf.add_font(\"DejaVu\", \"\", \"21798841561.ttf\", uni=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No more parts or failed to navigate: Message: no such element: Unable to locate element: {\"method\":\"tag name\",\"selector\":\"a\"}\n",
            "  (Session info: chrome=130.0.6723.116); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "#0 0x5956efea06da <unknown>\n",
            "#1 0x5956ef9b4f80 <unknown>\n",
            "#2 0x5956efa01b46 <unknown>\n",
            "#3 0x5956efa01de1 <unknown>\n",
            "#4 0x5956ef9f6616 <unknown>\n",
            "#5 0x5956efa25bdd <unknown>\n",
            "#6 0x5956ef9f6508 <unknown>\n",
            "#7 0x5956efa25d7e <unknown>\n",
            "#8 0x5956efa4469d <unknown>\n",
            "#9 0x5956efa25953 <unknown>\n",
            "#10 0x5956ef9f472e <unknown>\n",
            "#11 0x5956ef9f579e <unknown>\n",
            "#12 0x5956efe6bf1b <unknown>\n",
            "#13 0x5956efe6feb8 <unknown>\n",
            "#14 0x5956efe5942c <unknown>\n",
            "#15 0x5956efe70a37 <unknown>\n",
            "#16 0x5956efe3dfef <unknown>\n",
            "#17 0x5956efe8ead8 <unknown>\n",
            "#18 0x5956efe8eca0 <unknown>\n",
            "#19 0x5956efe9f556 <unknown>\n",
            "#20 0x7e485bf79ac3 <unknown>\n",
            "\n",
            "PDF saved as nhinnhangian.pdf\n"
          ]
        }
      ]
    }
  ]
}